正在学习中，Transformer相关内容


## Transformer 关键概念


## 遗留问题
输入嵌入、掩码注意力、位置编码

## 参考资料
| 名字 | 分类 | 内容 | 推荐指数 | 进度 |
| --- | ---- | --- | --- | --- |
| [深度解析 Transformer 和注意力机制](https://blog.csdn.net/jarodyv/article/details/130867562) | 中文博客 | 入门讲解，了解基础概念。| * | ✅ |
| [Self-Attention和Transformer](https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer#can-kao-zi-liao) | 中文博客 | 中文总结 | ** |  |
| [也来谈谈RNN的梯度消失/爆炸问题:](https://kexue.fm/archives/7888) | 中文博客 | RNN先相关问题 | *** |  |
| [【深度学习】Attention is All You Need : Transformer模型](https://www.hrwhisper.me/deep-learning-attention-is-all-you-need-transformer/) | 中文博客 | 【深度学习】Attention is All You Need : Transformer模型 | * |  |
| [【经典精读】万字长文解读Transformer模型和Attention机制](https://zhuanlan.zhihu.com/p/104393915?utm_source=ZHShareTargetIDMore) | 中文博客 | Transformer模型相关总结 | * |  |
| [一文搞懂one-hot和embedding](https://blog.csdn.net/Alex_81D/article/details/114287498) | 中文博客 |  | * |  |
| [深入理解Transformer及其源码](https://www.cnblogs.com/zingp/p/11696111.html) | 中文博客 |  | *** |  |
| [Transformer模型详解](https://blog.csdn.net/u012526436/article/details/86295971) | 中文博客 |  | * |  |
| [Self-Attention与Transformer](https://mp.weixin.qq.com/s/lUqpCae3TPkZlgT7gUatpg) | 中文博客 |  | * |  |
| [自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941) | 中文博客 |  | * |  |
| [《Attention is All You Need》浅读（简介+代码）](https://spaces.ac.cn/archives/4765) | 中文博客 |  | * |  |
| [【Transformer】10分钟学会Transformer](https://zhuanlan.zhihu.com/p/403433120) | 中文博客 |  | * |  |
| [突破瓶颈，打造更强大的Transformer](https://kexue.fm/archives/7325) | 中文博客 |  | * |  |
| [让研究人员绞尽脑汁的Transformer位置编码](https://spaces.ac.cn/archives/8130) | 中文博客 |  | * |  |
| [Transformers and Multi-Head Attention 源码教程](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html) | 中文博客 |  | * |  |
| [Transformers 源码学习](https://nn.labml.ai/transformers/index.html) | 中文博客 |  | * |  |
| [万字长文帮你彻底搞定Transformer-不要错过！！](https://zhuanlan.zhihu.com/p/153183322) | 中文总结 | Transformer知识总结 | * |  |
| [LLM Visualization](https://bbycroft.net/llm) | 交互式网站 | LLM可视化，交互式展示LLM流程，效果强大 | **** |  |
| [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) | 英文博客 | 带插图的Transformer讲解 | ***** |  |
| [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder-and-decoder-stacks) | 英文博客 | Transformer论文注释: 哈佛大学NLP组的notebook，很详细文字和代码描述，用pytorch实现 | ***** |  |
| [Attention Is All You NeedTransformers Explained Visually (Part 1): Overview of Functionality](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452/) | 英文博客 | 提供可视化的Transformer解读 | **** |  |
| [Transformers Explained Visually (Part 2): How it works, step-by-step](https://towardsdatascience.com/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34/) | 英文博客 |提供可视化的Transformer解读 | **** |  |
| [Transformers Explained Visually (Part 3): Multi-head Attention, deep dive](https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853/) | 英文博客 |提供可视化的Transformer解读 | **** |  |
| [What is Recurrent Neural Networks (RNN)?](https://www.analyticsvidhya.com/blog/2022/03/a-brief-overview-of-recurrent-neural-networks-rnn/) | 英文博客 | RNN香相关 | * |  |
| [Practical PyTorch: Translation with a Sequence to Sequence Network and Attention](https://notebook.community/spro/practical-pytorch/seq2seq-translation/seq2seq-translation-batched) | 英文博客 | 接入Pytorch的Transformer实战 | *** |  |
| [理解语言的 Transformer 模型](https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn) | 学习指南 | Google的TensorFlow官方的，用tf keras实现 | **** |  |
| [PyTorch Tutorials](https://docs.pytorch.org/tutorials/) | 学习指南 | PyTorch教程，使用手册，github地址：https://github.com/pytorch/tutorials | **** |  |
| [Fast.ai](https://www.fast.ai/) | 学习指南 |  |  |  |
| [Attention Is All You Need](https://arxiv.org/abs/1706.03762) | 论文 | Transformer论文 | ***** |  |
| [CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X](https://arxiv.org/pdf/2303.17568) | 论文 | Codegeex - transformer的结构图 |  |  |
|  |  |  |  |  |